{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi Oleh Kelompok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, nodes_n_in_hidden_layers, learning_rate, momentum):\n",
    "        nodes_n_in_hidden_layers.append(1) # satu node buat output\n",
    "        self.nodes_n_in_hidden_layers = nodes_n_in_hidden_layers\n",
    "        self.inputs = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.outputs = [] # output dari setiap node pada satu iterasi\n",
    "        self.weights = [] # weight dari setiap edge pada satu iterasi\n",
    "        self.biases = [] # bias dari setiap node pada satu iterasi\n",
    "        self.weight_biases = []\n",
    "        self.local_gradients = [] # local gradient dari setiap node pada satu iterasi\n",
    "        self.delta_weights = [] # delta weight dari setiap edge pada satu iterasi\n",
    "        self.delta_biases = [] # delta bias dari setiap node pada satu iterasi\n",
    "        self.layer_nodes = [] # node-node pada layer-layer\n",
    "        self.v = [] # v pada setiap node\n",
    "        self.targets = []\n",
    "    \n",
    "    # Feed Forward\n",
    "    def feed_forward(self, datum_idx):\n",
    "        print(\"self.inputs: \",self.inputs)\n",
    "        for i in range (1, len(self.layer_nodes)):\n",
    "            for j in range (0, len(self.layer_nodes[i])):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                weights = []\n",
    "                weights.append(self.biases[current_node])\n",
    "                inputs = []\n",
    "                inputs.append(1)\n",
    "                for k in range(0, len(self.layer_nodes[i-1])):\n",
    "                    if (self.weights[self.layer_nodes[i-1][k]][current_node] != None):\n",
    "                            weights.append(self.weights[self.layer_nodes[i-1][k]][current_node])\n",
    "                    \n",
    "                    if (i==1):\n",
    "                        inputs.append(self.inputs[datum_idx][self.layer_nodes[i-1][k]])\n",
    "                    else:\n",
    "                        inputs.append(self.outputs[self.layer_nodes[i-1][k]])\n",
    "                print(\"inputs\", inputs)\n",
    "                print(\"weights\", weights)\n",
    "                v = np.dot(inputs, weights)\n",
    "                self.v[current_node] = v\n",
    "                self.outputs[current_node] = sigmoid(v)\n",
    "        print(\"done ff\")\n",
    "                \n",
    "    # Back Propagation\n",
    "    def back_propagation(self, datum_idx):\n",
    "        for i in range(len(self.layer_nodes)-1, 0, -1):\n",
    "            for j in range(len(self.layer_nodes[i])-1, -1, -1):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                if (i == len(self.layer_nodes)-1):\n",
    "                    v = self.v[current_node]\n",
    "                    sig_v = sigmoid(v)\n",
    "                    self.local_gradients[current_node] = self.local_gradients[current_node] + (sig_v * (1 - sig_v) * (self.targets[datum_idx] - self.outputs[current_node]))\n",
    "                else:\n",
    "                    v = self.v[current_node]\n",
    "                    sig_v = sigmoid(v)\n",
    "                    weight_delta = 1\n",
    "                    for k in range(0, len(self.layer_nodes[i+1])):\n",
    "                        if (self.weights[current_node][self.layer_nodes[i+1][k]] != None):\n",
    "                            weight_delta = weight_delta * self.local_gradients[self.layer_nodes[i+1][k]] * self.weights[current_node][self.layer_nodes[i+1][k]]\n",
    "                    self.local_gradients[current_node] = self.local_gradients[current_node] + (sig_v * (1 - sig_v) * weight_delta)            \n",
    "                \n",
    "    # Update Weight\n",
    "    def update_weight(self):\n",
    "        for i in range(0, len(self.layer_nodes)-1):\n",
    "            for j in range(0, len(self.layer_nodes[i])):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                for k in range(0, len(self.layer_nodes[i+1])):\n",
    "                    current_next_node = self.layer_nodes[i+1][k]\n",
    "                    new_weight = self.weights[current_node][current_next_node] + self.momentum * self.delta_weights[current_node][current_next_node] + self.learning_rate * self.local_gradients[current_next_node] * self.outputs[current_node]\n",
    "                    self.delta_weights[current_node][current_next_node] = new_weight - self.weights[current_node][current_next_node]\n",
    "                    self.weights[current_node][current_next_node] = new_weight\n",
    "        for i in range(1, len(self.biases)):\n",
    "            new_bias = self.biases[i] + self.momentum  * self.delta_biases[i] + self.learning_rate * self.local_gradients[i]\n",
    "            self.delta_biases[i] = new_bias - self.biases[i]\n",
    "            self.biases[i] = new_bias\n",
    "            \n",
    "    # Fit\n",
    "    def fit(self, data, batch_size, max_iter): # data = array of arrays\n",
    "        #data[0] ke n merupakan label\n",
    "        #nodes_n_in_hidden_layers[0] merupakan jumlah input\n",
    "        self.nodes_n_in_hidden_layers.insert(0, len(data[0])-1) \n",
    "        \n",
    "        inputs = data\n",
    "        print(\"inputs: \", inputs)\n",
    "        for i in range (0, len(inputs)):\n",
    "            print(\"len(inputs[i]): \", len(inputs[i]))\n",
    "            self.targets.append(inputs[i].pop(len(inputs[i])-1))\n",
    "        self.inputs = inputs\n",
    "        print(\"self.targets: \", self.targets)\n",
    "        print(\"self.inputs: \", self.inputs)\n",
    "        \n",
    "        n_nodes = 0\n",
    "        init_weight = 1 # Weights diinisalisasi 0\n",
    "        \n",
    "        # Inisialisasi output, bias, local gradient, v, dan delta bias di setiap node pada layer\n",
    "        for i in range(0, len(self.nodes_n_in_hidden_layers)):\n",
    "            l_nodes = []\n",
    "            for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                self.outputs.append(0)\n",
    "                sts\n",
    "                elf.v.append(0)\n",
    "                self.biases.append(0) #asumsi x bias = 1\n",
    "                self.local_gradients.append(0)\n",
    "                self.delta_biases.append(0)\n",
    "                l_nodes.append(n_nodes)\n",
    "                n_nodes += 1\n",
    "            self.layer_nodes.append(l_nodes)\n",
    "        \n",
    "        for i in range(0, n_nodes):\n",
    "            values = []\n",
    "            for j in range(0, n_nodes):\n",
    "                values.append(None)\n",
    "            self.weights.append(values)\n",
    "            self.delta_weights.append(values)\n",
    "            \n",
    "        current_node = 0\n",
    "        for i in range(0, len(self.nodes_n_in_hidden_layers)-1):\n",
    "            if (i < len(self.nodes_n_in_hidden_layers)-1):\n",
    "                next_layer_first_node = current_node + self.nodes_n_in_hidden_layers[i]\n",
    "                for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                    for k in range(0, self.nodes_n_in_hidden_layers[i+1]):\n",
    "                        self.weights[current_node][k+next_layer_first_node] = init_weight\n",
    "                        self.local_gradients[current_node] = 0\n",
    "                        self.delta_weights[current_node][k+next_layer_first_node] = init_weight\n",
    "                    current_node += 1\n",
    "        \n",
    "        print(\"self.layer_nodes: \",self.layer_nodes)\n",
    "        print(\"self.nodes_n_in_hidden_layers: \",self.nodes_n_in_hidden_layers)\n",
    "        \n",
    "        n_batch = math.ceil(len(data)/batch_size)\n",
    "        \n",
    "        n_iter = 0\n",
    "        while (n_iter < max_iter):\n",
    "            \n",
    "            datum_idx = 0\n",
    "            for i in range(0, n_batch):\n",
    "                j = 0\n",
    "                while (j < batch_size):\n",
    "                    if (datum_idx < len(data)):\n",
    "                        self.feed_forward(datum_idx)\n",
    "                        self.back_propagation(datum_idx)\n",
    "                        datum_idx += 1\n",
    "                        j += 1\n",
    "                    else:\n",
    "                        j = batch_size + 1\n",
    "                print(\"local gradients\")\n",
    "                print(self.local_gradients)\n",
    "                self.update_weight()\n",
    "                # Mengembalikan local_gradient menjadi 0\n",
    "                current_node = 0\n",
    "                for i in range(0, len(self.nodes_n_in_hidden_layers)-1):\n",
    "                    if (i < len(self.nodes_n_in_hidden_layers)-1):\n",
    "                        next_layer_first_node = current_node + self.nodes_n_in_hidden_layers[i]\n",
    "                        for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                            for k in range(0, self.nodes_n_in_hidden_layers[i+1]):\n",
    "                                self.local_gradients[current_node] = 0\n",
    "                            current_node += 1\n",
    "                        \n",
    "            n_iter += 1\n",
    "            \n",
    "        print(\"self.weights: \",self.weights)\n",
    "        \n",
    "    # Predict\n",
    "    def predict(self, data_test):\n",
    "        test_outputs = []\n",
    "        feed_forward_result = []\n",
    "        self.inputs = data_test\n",
    "        \n",
    "        for i in range (0, len(data_test)):\n",
    "            self.feed_forward(i)\n",
    "            print(self.outputs)\n",
    "            test_outputs.append(self.outputs[-1])\n",
    "        \n",
    "        return test_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting dengan Hasil Implementasi Kelompok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  [[0.1, 0.9, 0.9], [0.1, 0.88, 0.9]]\n",
      "len(inputs[i]):  3\n",
      "len(inputs[i]):  3\n",
      "self.targets:  [0.9, 0.9]\n",
      "self.inputs:  [[0.1, 0.9], [0.1, 0.88]]\n",
      "self.layer_nodes:  [[0, 1], [2, 3, 4], [5, 6], [7]]\n",
      "self.nodes_n_in_hidden_layers:  [2, 3, 2, 1]\n",
      "self.inputs:  [[0.1, 0.9], [0.1, 0.88]]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [0, 1, 1]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [0, 1, 1]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [0, 1, 1]\n",
      "inputs [1, 0.7310585786300049, 0.7310585786300049, 0.7310585786300049]\n",
      "weights [0, 1, 1, 1]\n",
      "inputs [1, 0.7310585786300049, 0.7310585786300049, 0.7310585786300049]\n",
      "weights [0, 1, 1, 1]\n",
      "inputs [1, 0.899635013659718, 0.899635013659718]\n",
      "weights [0, 1, 1]\n",
      "done ff\n",
      "local gradients\n",
      "[0, 0, 4.182225429418306e-08, 4.182225429418306e-08, 4.182225429418306e-08, 0.00046121007144219134, 0.00046121007144219134, 0.0051079919341964555]\n",
      "self.inputs:  [[0.1, 0.9], [0.1, 0.88]]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [1.0455563573545766e-08, 1.0001, 1.0001]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [1.0455563573545766e-08, 1.0001, 1.0001]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [1.0455563573545766e-08, 1.0001, 1.0001]\n",
      "inputs [1, 0.7271276633249473, 0.7271276633249473, 0.7271276633249473]\n",
      "weights [0.00011530251786054783, 1.0001842928948195, 1.0001842928948195, 1.0001842928948195]\n",
      "inputs [1, 0.7271276633249473, 0.7271276633249473, 0.7271276633249473]\n",
      "weights [0.00011530251786054783, 1.0001842928948195, 1.0001842928948195, 1.0001842928948195]\n",
      "inputs [1, 0.8986123367531913, 0.8986123367531913]\n",
      "weights [0.0012769979835491139, 1.0012488320983737, 1.0012488320983737]\n",
      "done ff\n",
      "local gradients\n",
      "[0, 0, 4.2567380129412806e-07, 4.2567380129412806e-07, 4.2567380129412806e-07, 0.0013906458013110481, 0.0013906458013110481, 0.010188725247518165]\n",
      "self.inputs:  [[0.1, 0.9], [0.1, 0.88]]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [1.1687505945343513e-07, 1.00020001, 1.00020001]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [1.1687505945343513e-07, 1.00020001, 1.00020001]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [1.1687505945343513e-07, 1.00020001, 1.00020001]\n",
      "inputs [1, 0.7310979241422955, 0.7310979241422955, 0.7310979241422955]\n",
      "weights [0.0004629754984400959, 1.000537105582114, 1.000537105582114, 1.000537105582114]\n",
      "inputs [1, 0.7310979241422955, 0.7310979241422955, 0.7310979241422955]\n",
      "weights [0.0004629754984400959, 1.000537105582114, 1.000537105582114, 1.000537105582114]\n",
      "inputs [1, 0.8997937292452667, 0.8997937292452667]\n",
      "weights [0.0038243069952270097, 1.0036378855323855, 1.0036378855323855]\n",
      "done ff\n",
      "local gradients\n",
      "[0, 0, 3.6751515256868e-07, 3.6751515256868e-07, 3.6751515256868e-07, 0.0013665312656838847, 0.0013665312656838847, 0.015100963705990195]\n",
      "self.inputs:  [[0.1, 0.9], [0.1, 0.88]]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [2.0876448954519313e-07, 1.0003000300009999, 1.0003000300009999]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [2.0876448954519313e-07, 1.0003000300009999, 1.0003000300009999]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [2.0876448954519313e-07, 1.0003000300009999, 1.0003000300009999]\n",
      "inputs [1, 0.7271665957230777, 0.7271665957230777, 0.7271665957230777]\n",
      "weights [0.0008046430821591251, 1.0008869263355764, 1.0008869263355764, 1.0008869263355764]\n",
      "inputs [1, 0.7271665957230777, 0.7271665957230777, 0.7271665957230777]\n",
      "weights [0.0008046430821591251, 1.0008869263355764, 1.0008869263355764, 1.0008869263355764]\n",
      "inputs [1, 0.8988252360615889, 0.8988252360615889]\n",
      "weights [0.007599802652625726, 1.0071351874329915, 1.0071351874329915]\n",
      "done ff\n",
      "local gradients\n",
      "[0, 0, 2.385044731930842e-06, 2.385044731930842e-06, 2.385044731930842e-06, 0.003186098570688908, 0.003186098570688908, 0.01986702771633126]\n",
      "self.inputs:  [[0.1, 0.9], [0.1, 0.88]]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [8.050348614709128e-07, 1.000400060004, 1.000400060004]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [8.050348614709128e-07, 1.000400060004, 1.000400060004]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [8.050348614709128e-07, 1.000400060004, 1.000400060004]\n",
      "inputs [1, 0.7311373861797933, 0.7311373861797933, 0.7311373861797933]\n",
      "weights [0.001601201891589724, 1.0015662211410314, 1.0015662211410314, 1.0015662211410314]\n",
      "inputs [1, 0.7311373861797933, 0.7311373861797933, 0.7311373861797933]\n",
      "weights [0.001601201891589724, 1.0015662211410314, 1.0015662211410314, 1.0015662211410314]\n",
      "inputs [1, 0.9001101197079227, 0.9001101197079227]\n",
      "weights [0.01256693713127428, 1.0117001474209781, 1.0117001474209781]\n",
      "done ff\n",
      "local gradients\n",
      "[0, 0, 9.67854814297641e-07, 9.67854814297641e-07, 9.67854814297641e-07, 0.00221544378234547, 0.00221544378234547, 0.024355204684566548]\n",
      "self.inputs:  [[0.1, 0.9], [0.1, 0.88]]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [1.0470581920825157e-06, 1.0005001000100004, 1.0005001000100004]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [1.0470581920825157e-06, 1.0005001000100004, 1.0005001000100004]\n",
      "inputs [1, 0.1, 0.88]\n",
      "weights [1.0470581920825157e-06, 1.0005001000100004, 1.0005001000100004]\n",
      "inputs [1, 0.7272056593870464, 0.7272056593870464, 0.7272056593870464]\n",
      "weights [0.0021551424930570345, 1.0020713262072087, 1.0020713262072087, 1.0020713262072087]\n",
      "inputs [1, 0.7272056593870464, 0.7272056593870464, 0.7272056593870464]\n",
      "weights [0.0021551424930570345, 1.0020713262072087, 1.0020713262072087, 1.0020713262072087]\n",
      "inputs [1, 0.8991930964764685, 0.8991930964764685]\n",
      "weights [0.018656235015863783, 1.0172819089867544, 1.0172819089867544]\n",
      "done ff\n",
      "local gradients\n",
      "[0, 0, 5.658526726436378e-06, 5.658526726436378e-06, 5.658526726436378e-06, 0.0048525787311919, 0.0048525787311919, 0.028598798931329078]\n",
      "self.weights:  [[None, None, 1.0006001500200015, 1.0006001500200015, 1.0006001500200015, None, None, None], [None, None, 1.0006001500200015, 1.0006001500200015, 1.0006001500200015, None, None, None], [None, None, None, None, None, 1.0030537390188154, 1.0030537390188154, None], [None, None, None, None, None, 1.0030537390188154, 1.0030537390188154, None], [None, None, None, None, None, 1.0030537390188154, 1.0030537390188154, None], [None, None, None, None, None, None, None, 1.0238125978192953], [None, None, None, None, None, None, None, 1.0238125978192953], [None, None, None, None, None, None, None, None]]\n",
      "self.inputs:  [[0.9, 0.1], [0.1, 0.9]]\n",
      "inputs [1, 0.9, 0.1]\n",
      "weights [2.461714076024671e-06, 1.0006001500200015, 1.0006001500200015]\n",
      "inputs [1, 0.9, 0.1]\n",
      "weights [2.461714076024671e-06, 1.0006001500200015, 1.0006001500200015]\n",
      "inputs [1, 0.9, 0.1]\n",
      "weights [2.461714076024671e-06, 1.0006001500200015, 1.0006001500200015]\n",
      "inputs [1, 0.7311770427896659, 0.7311770427896659, 0.7311770427896659]\n",
      "weights [0.003368342569915156, 1.0030537390188154, 1.0030537390188154, 1.0030537390188154]\n",
      "inputs [1, 0.7311770427896659, 0.7311770427896659, 0.7311770427896659]\n",
      "weights [0.003368342569915156, 1.0030537390188154, 1.0030537390188154, 1.0030537390188154]\n",
      "inputs [1, 0.9005721423423267, 0.9005721423423267]\n",
      "weights [0.025806543678484513, 1.0238125978192953, 1.0238125978192953]\n",
      "done ff\n",
      "[0, 0, 0.7311770427896659, 0.7311770427896659, 0.7311770427896659, 0.9005721423423267, 0.9005721423423267, 0.8664398501670865]\n",
      "self.inputs:  [[0.9, 0.1], [0.1, 0.9]]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [2.461714076024671e-06, 1.0006001500200015, 1.0006001500200015]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [2.461714076024671e-06, 1.0006001500200015, 1.0006001500200015]\n",
      "inputs [1, 0.1, 0.9]\n",
      "weights [2.461714076024671e-06, 1.0006001500200015, 1.0006001500200015]\n",
      "inputs [1, 0.7311770427896659, 0.7311770427896659, 0.7311770427896659]\n",
      "weights [0.003368342569915156, 1.0030537390188154, 1.0030537390188154, 1.0030537390188154]\n",
      "inputs [1, 0.7311770427896659, 0.7311770427896659, 0.7311770427896659]\n",
      "weights [0.003368342569915156, 1.0030537390188154, 1.0030537390188154, 1.0030537390188154]\n",
      "inputs [1, 0.9005721423423267, 0.9005721423423267]\n",
      "weights [0.025806543678484513, 1.0238125978192953, 1.0238125978192953]\n",
      "done ff\n",
      "[0, 0, 0.7311770427896659, 0.7311770427896659, 0.7311770427896659, 0.9005721423423267, 0.9005721423423267, 0.8664398501670865]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8664398501670865, 0.8664398501670865]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNet([3,2], 0.25, 0.0001) \n",
    "nn.fit([[0.1,0.9,0.9],[0.1,0.88,0.9]], 1, 3)\n",
    "data_test = [[0.9,0.1],[0.1,0.9]]\n",
    "nn.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi dengan Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "class KerasNeuralNet:\n",
    "    \n",
    "    # Construction\n",
    "    def __init__(self, nodes_n_in_hidden_layers, learning_rate, momentum):\n",
    "        nodes_n_in_hidden_layers.append(1) # satu node buat output\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(output_dim=nodes_n_in_hidden_layers[0], input_dim=4, activation=\"sigmoid\"))\n",
    "        for i in range(1, len(nodes_n_in_hidden_layers)):\n",
    "            self.model.add(Dense(output_dim=nodes_n_in_hidden_layers[i], input_dim=nodes_n_in_hidden_layers[i-1], activation='sigmoid'))\n",
    "        sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=True)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, X, Y, batch_size):\n",
    "        print(X, Y, batch_size)\n",
    "        self.model.fit(X, Y, batch_size=batch_size)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting dengan Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suzaneringoringo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/suzaneringoringo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=4, activation=\"sigmoid\", units=2)`\n",
      "  del sys.path[0]\n",
      "/home/suzaneringoringo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=2, activation=\"sigmoid\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   0.5  0.   0. ]\n",
      " [ 1.   0.5  0.   1. ]\n",
      " [ 0.   0.5  0.   0. ]\n",
      " [ 0.5  1.   0.   0. ]\n",
      " [ 0.5  0.   1.   0. ]\n",
      " [ 0.5  0.   1.   1. ]\n",
      " [ 0.   0.   1.   1. ]\n",
      " [ 1.   1.   0.   0. ]\n",
      " [ 1.   0.   1.   0. ]\n",
      " [ 0.5  1.   1.   0. ]\n",
      " [ 1.   1.   1.   1. ]\n",
      " [ 0.   1.   0.   1. ]\n",
      " [ 0.   0.5  1.   0. ]\n",
      " [ 0.5  1.   0.   1. ]] [0 0 1 1 1 0 1 0 1 1 1 1 1 0] 1\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 1s 82ms/step - loss: 0.8824 - acc: 0.3571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.18783519],\n",
       "       [ 0.22113007],\n",
       "       [ 0.25110272],\n",
       "       [ 0.21877776],\n",
       "       [ 0.3226575 ],\n",
       "       [ 0.36289889],\n",
       "       [ 0.39556172],\n",
       "       [ 0.18942542],\n",
       "       [ 0.28445289],\n",
       "       [ 0.32363689],\n",
       "       [ 0.32989258],\n",
       "       [ 0.29406101],\n",
       "       [ 0.35958937],\n",
       "       [ 0.25698826]], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv('tennis.csv')\n",
    "\n",
    "# Transform outlook, temperature, humidity, and windy to numerical values\n",
    "le = preprocessing.LabelEncoder()\n",
    "encoded = dataframe.apply(le.fit_transform)\n",
    "dataset = encoded.values\n",
    "\n",
    "# X and Y values\n",
    "X = dataset[:,0:4]\n",
    "Y = dataset[:,4]\n",
    "\n",
    "# Rescale min and max for X\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "knn = KerasNeuralNet([2], 0.25, 0.0001)\n",
    "\n",
    "# Train model\n",
    "knn.fit(rescaledX, Y, 1)\n",
    "\n",
    "# Predict\n",
    "knn.predict(rescaledX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
