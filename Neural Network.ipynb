{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi Oleh Kelompok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class NeuralNet:\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, nodes_n_in_hidden_layers, learning_rate, momentum):\n",
    "        nodes_n_in_hidden_layers.append(1) # satu node buat output\n",
    "        self.nodes_n_in_hidden_layers = nodes_n_in_hidden_layers\n",
    "        self.inputs = [] #data input\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.outputs = [] # output dari setiap node pada satu iterasi\n",
    "        self.weights = [] # weight dari setiap edge pada satu iterasi\n",
    "        self.biases = [] # bias dari setiap node pada satu iterasi\n",
    "        self.weight_biases = []\n",
    "        self.local_gradients = [] # local gradient dari setiap node pada satu iterasi\n",
    "        self.delta_weights = [] # delta weight dari setiap edge pada satu iterasi\n",
    "        self.delta_biases = [] # delta bias dari setiap node pada satu iterasi\n",
    "        self.layer_nodes = [] # node-node pada layer-layer\n",
    "        self.v = [] # v pada setiap node\n",
    "        self.targets = [] # target dari data input\n",
    "        self.test_outputs = [] # hasil predict data test\n",
    "        self.test_labels = [] # label hasil predict data test\n",
    "        \n",
    "    # Feed Forward\n",
    "    def feed_forward(self, datum_idx):\n",
    "        for i in range (1, len(self.layer_nodes)):\n",
    "            for j in range (0, len(self.layer_nodes[i])):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                weights = []\n",
    "                weights.append(self.biases[current_node])\n",
    "                inputs = []\n",
    "                inputs.append(1)\n",
    "                for k in range(0, len(self.layer_nodes[i-1])):\n",
    "                    if (self.weights[self.layer_nodes[i-1][k]][current_node] != None):\n",
    "                            weights.append(self.weights[self.layer_nodes[i-1][k]][current_node])\n",
    "                    \n",
    "                    if (i==1):\n",
    "                        inputs.append(self.inputs[datum_idx][self.layer_nodes[i-1][k]])\n",
    "                    else:\n",
    "                        inputs.append(self.outputs[self.layer_nodes[i-1][k]])\n",
    "                v = np.dot(inputs, weights)\n",
    "                self.v[current_node] = v\n",
    "                self.outputs[current_node] = sigmoid(v)\n",
    "                \n",
    "    # Back Propagation\n",
    "    def back_propagation(self, datum_idx):\n",
    "        for i in range(len(self.layer_nodes)-1, 0, -1):\n",
    "            for j in range(len(self.layer_nodes[i])-1, -1, -1):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                if (i == len(self.layer_nodes)-1):\n",
    "                    v = self.v[current_node]\n",
    "                    sig_v = sigmoid(v)\n",
    "                    self.local_gradients[current_node] = self.local_gradients[current_node] + (sig_v * (1 - sig_v) * (self.targets[datum_idx] - self.outputs[current_node]))\n",
    "                else:\n",
    "                    v = self.v[current_node]\n",
    "                    sig_v = sigmoid(v)\n",
    "                    weight_delta = 1\n",
    "                    for k in range(0, len(self.layer_nodes[i+1])):\n",
    "                        weight_delta = weight_delta * self.local_gradients[self.layer_nodes[i+1][k]] * self.weights[current_node][self.layer_nodes[i+1][k]]\n",
    "                    self.local_gradients[current_node] = self.local_gradients[current_node] + (sig_v * (1 - sig_v) * weight_delta)            \n",
    "                \n",
    "    # Update Weight\n",
    "    def update_weight(self):\n",
    "        for i in range(0, len(self.layer_nodes)-1):\n",
    "            for j in range(0, len(self.layer_nodes[i])):\n",
    "                current_node = self.layer_nodes[i][j]\n",
    "                for k in range(0, len(self.layer_nodes[i+1])):\n",
    "                    current_next_node = self.layer_nodes[i+1][k]\n",
    "                    self.delta_weights[current_node][current_next_node] = self.momentum * self.delta_weights[current_node][current_next_node] + self.learning_rate * self.local_gradients[current_next_node] * self.outputs[current_next_node]\n",
    "                    self.weights[current_node][current_next_node] += self.delta_weights[current_node][current_next_node]\n",
    "        for i in range(1, len(self.biases)):\n",
    "            new_bias = self.biases[i] + self.momentum  * self.delta_biases[i] + self.learning_rate * self.local_gradients[i]\n",
    "            self.delta_biases[i] = new_bias - self.biases[i]\n",
    "            self.biases[i] = new_bias\n",
    "            \n",
    "    # Fit\n",
    "    def fit(self, X, Y, batch_size, max_iter, threshold): # data = array of arrays\n",
    "        #data[0] ke n merupakan label\n",
    "        #nodes_n_in_hidden_layers[0] merupakan jumlah input\n",
    "        self.nodes_n_in_hidden_layers.insert(0, len(X[0])) \n",
    "        \n",
    "        self.targets = Y\n",
    "        self.inputs = X\n",
    "        \n",
    "        n_nodes = 0\n",
    "        init_weight = 1 # Weights diinisalisasi 0\n",
    "        \n",
    "        # Inisialisasi output, bias, local gradient, v, dan delta bias di setiap node pada layer\n",
    "        for i in range(0, len(self.nodes_n_in_hidden_layers)):\n",
    "            l_nodes = []\n",
    "            for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                self.outputs.append(0)\n",
    "                self.v.append(0)\n",
    "                self.biases.append(0) #asumsi x bias = 1\n",
    "                self.local_gradients.append(0)\n",
    "                self.delta_biases.append(0)\n",
    "                l_nodes.append(n_nodes)\n",
    "                n_nodes += 1\n",
    "            self.layer_nodes.append(l_nodes)\n",
    "        \n",
    "        for i in range(0, n_nodes):\n",
    "            self.weights.append([])\n",
    "            self.delta_weights.append([])\n",
    "            for j in range(0, n_nodes):\n",
    "                self.weights[i].append(None)\n",
    "                self.delta_weights[i].append(None)\n",
    "            \n",
    "        current_node = 0\n",
    "        for i in range(0, len(self.nodes_n_in_hidden_layers)-1):\n",
    "            if (i < len(self.nodes_n_in_hidden_layers)-1):\n",
    "                next_layer_first_node = current_node + self.nodes_n_in_hidden_layers[i]\n",
    "                for j in range(0, self.nodes_n_in_hidden_layers[i]):\n",
    "                    for k in range(0, self.nodes_n_in_hidden_layers[i+1]):\n",
    "                        self.weights[current_node][k+next_layer_first_node] = random.uniform(-0.5,0.5)\n",
    "                        self.delta_weights[current_node][k+next_layer_first_node] = 0\n",
    "                    current_node += 1\n",
    "        \n",
    "        n_batch = math.ceil(len(Y)/batch_size)\n",
    "        \n",
    "        n_iter = 0\n",
    "        error = 100\n",
    "        while (n_iter < max_iter and error > threshold):\n",
    "            datum_idx = 0\n",
    "            for i in range(0, n_batch):\n",
    "                # Mengembalikan local_gradient menjadi 0\n",
    "                for i in range(0, n_nodes):\n",
    "                    self.local_gradients[i] = 0\n",
    "                    \n",
    "                j = 0\n",
    "                accum_error = 0\n",
    "                num_datum = 0\n",
    "                while (j < batch_size):\n",
    "                    if (datum_idx < len(Y)):\n",
    "                        self.feed_forward(datum_idx)\n",
    "                        accum_error = accum_error + (0.5 * ((self.targets[datum_idx] - self.outputs[-1])**2))\n",
    "                        num_datum = num_datum + 1\n",
    "                        self.back_propagation(datum_idx)\n",
    "                        datum_idx += 1\n",
    "                        j += 1\n",
    "                    else:\n",
    "                        j = batch_size + 1\n",
    "                error = accum_error / num_datum\n",
    "                if (error < threshold):\n",
    "                    break\n",
    "                self.update_weight()\n",
    "            \n",
    "            n_iter += 1\n",
    "        \n",
    "    # Predict\n",
    "    def predict(self, data_test):\n",
    "        feed_forward_result = []\n",
    "        self.inputs = data_test\n",
    "        \n",
    "        for i in range (0, len(data_test)):\n",
    "            self.feed_forward(i)\n",
    "            self.test_outputs.append(self.outputs[-1])\n",
    "        \n",
    "        return self.test_outputs\n",
    "    \n",
    "    def predict_label(self):\n",
    "        for i in range (0, len(self.test_outputs)):\n",
    "            if self.test_outputs[i] >= 0.5:\n",
    "                self.test_labels.append(1)\n",
    "            else:\n",
    "                self.test_labels.append(0)\n",
    "        return self.test_labels\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penjelasan Model Neural Network\n",
    "Model Neural Network pada program kami diimplementasikan dengan mendefinisikan variabel-variabel (inputs, outputs, jumlah node pada satu layer, dll) dalam bentuk matrix dan list. Pada saat penciptaan suatu obyek Neural Network, diperlukan parameter jumlah node di setiap layer, learning rate, dan momentum. Setelah itu, obyek Neural Network yang terbentuk akan menginisiasi beberapa variabel seperti weights, biases, delta weights, delta biases, local gradients, dan beberapa variabel lainnya. \n",
    "\n",
    "Pada kelas Neural Network, terdapat sejumlah fungsi, yaitu: \n",
    "1. Feed forward\n",
    "2. Back propagation\n",
    "3. Update weight\n",
    "4. Fit\n",
    "5. Predict\n",
    "6. Predict label\n",
    "\n",
    "### 1. Feed Forward\n",
    "Pada fungsi ini, program akan melakukan pembelajaran terhadap setiap node dengan memasukkan seluruh weight (termasuk weight bias) dan seluruh nilai (termasuk bias) yang menuju ke node tersebut ke dalam list weight dan list input. Kedua list tersebut kemudian di kalikan secara dot matrix yang kemudian hasil tersebut akan dimasukkan ke dalam fungsi sigmoid untuk mendapatkan satu output dari node tersebut. Hasil output tersebut kemudian dijadikan input untuk menghitung output pada node selanjutnya.\n",
    "\n",
    "### 2. Back Propagation\n",
    "Pada fungsi back propagation, dilakukan perhitungan untuk memperbarui nilai local gradient setiap node.\n",
    "\n",
    "### 3. Update Weight\n",
    "Pada fungsi update weight, dilakukan perhitungan untuk mendapatkan delta weight dan weight baru. Adapun delta_weight = momentum * delta_weight sebelumnya +  learning_rate * local_gradient * output.\n",
    "\n",
    "### 4. Fit\n",
    "Pada fungsi ini program melakukan pembelajaran terhadap data input. Pembelajaran dilakukan dengan mengkombinasikan ketiga fungsi sebelumnya yaitu feed forward, back propagation, dan update weight yang dieksekusi secara berurutan yang dilakukan sebanyak max_iter atau dilakukan hingga error yang dihasilkan <= threshold.\n",
    "\n",
    "Selain itu pada fungsi ini diimplementasikan juga mini-batch stochastic gradient descent. Implementasi dilakukan dengan cara menerima input berupa batch_size. Program kemudian akan melakukan update weight setelah dilakukan feed forward dan back propagation sebanyak n_batch kali, di mana n_batch adalah jumlah datum dibagi dengan batch_size. Jika nilainya tidak bulat, diambil pembulatan ke atas.\n",
    "\n",
    "### 5. Predict\n",
    "Pada fungsi ini program melakukan prediksi terhadap data test. Prediksi dilakukan dengan cara memanfaatkan model hasil fit dan menjalankan fungsi feed forward untuk setiap data test. \n",
    "\n",
    "### 6. Predict Label\n",
    "Fungsi ini hanya mengembalikan label hasil prediksi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementasi dengan Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "class KerasNeuralNet:\n",
    "    \n",
    "    # Construction\n",
    "    def __init__(self, nodes_n_in_hidden_layers, learning_rate, momentum):\n",
    "        nodes_n_in_hidden_layers.append(1) # satu node buat output\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(output_dim=nodes_n_in_hidden_layers[0], input_dim=4, activation=\"sigmoid\"))\n",
    "        for i in range(1, len(nodes_n_in_hidden_layers)):\n",
    "            self.model.add(Dense(output_dim=nodes_n_in_hidden_layers[i], input_dim=nodes_n_in_hidden_layers[i-1], activation='sigmoid'))\n",
    "        sgd = optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=True)\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, X, Y, batch_size):\n",
    "        self.model.fit(X, Y, batch_size=batch_size)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membaca Data Tennis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suzaneringoringo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load data\n",
    "dataframe = pd.read_csv('tennis.csv')\n",
    "\n",
    "# Transform outlook, temperature, humidity, and windy to numerical values\n",
    "le = preprocessing.LabelEncoder()\n",
    "encoded = dataframe.apply(le.fit_transform)\n",
    "dataset = encoded.values\n",
    "\n",
    "# X and Y values\n",
    "X = dataset[:,0:4]\n",
    "Y = dataset[:,4]\n",
    "\n",
    "# Rescale min and max for X\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting dengan Hasil Implementasi Kelompok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNet([6], 0.25, 0.0001)\n",
    "nn.fit(rescaledX, Y, 1, 5, 0.01)\n",
    "nn.predict(rescaledX)\n",
    "nn.predict_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting dengan Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suzaneringoringo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=4, activation=\"sigmoid\", units=6)`\n",
      "  del sys.path[0]\n",
      "/home/suzaneringoringo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=6, activation=\"sigmoid\", units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 0.6945 - acc: 0.6429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.49518728],\n",
       "       [ 0.50273669],\n",
       "       [ 0.52284312],\n",
       "       [ 0.51959115],\n",
       "       [ 0.52425283],\n",
       "       [ 0.53473157],\n",
       "       [ 0.54785746],\n",
       "       [ 0.50684351],\n",
       "       [ 0.50934798],\n",
       "       [ 0.54529226],\n",
       "       [ 0.53976887],\n",
       "       [ 0.54391503],\n",
       "       [ 0.55013728],\n",
       "       [ 0.52857137]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KerasNeuralNet([6], 0.25, 0.0001)\n",
    "\n",
    "# Train model\n",
    "knn.fit(rescaledX, Y, 1)\n",
    "\n",
    "# Predict\n",
    "knn.predict(rescaledX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pembagian Tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Helena Suzane Graciella (13515032)\n",
    "    - Update Weight\n",
    "    - Implementasi Keras\n",
    "    - Fit\n",
    "    - Laporan\n",
    "2. Lathifah Nurrahmah (13515046)\n",
    "    - Back Propagation\n",
    "    - Fit\n",
    "    - Predict\n",
    "    - Laporan\n",
    "3. Aya Aurora Rimbamorani (13515098)\n",
    "    - Feed Forward\n",
    "    - Fit\n",
    "    - Predict & Predict Label\n",
    "    - Laporan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
